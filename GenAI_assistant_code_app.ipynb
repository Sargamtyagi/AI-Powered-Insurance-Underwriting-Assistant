{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/utils.py')  # location where utils.py is uploaded\n",
        "import utils\n"
      ],
      "metadata": {
        "id": "hv9OCZ6s1b_2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Main entry point for the app.\n",
        "\n",
        "This app is generated based on your prompt in Vertex AI Studio using\n",
        "Google GenAI Python SDK (https://googleapis.github.io/python-genai/) and\n",
        "Gradio (https://www.gradio.app/).\n",
        "\n",
        "You can customize the app by editing the code in Cloud Run source code editor.\n",
        "You can also update the prompt in Vertex AI Studio and redeploy it.\n",
        "\"\"\"\n",
        "\n",
        "import base64\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def generate(\n",
        "    message,\n",
        "    history: list[gr.ChatMessage],\n",
        "    request: gr.Request\n",
        "):\n",
        "  \"\"\"Function to call the model based on the request.\"\"\"\n",
        "\n",
        "  validate_key_result = utils.validate_key(request)\n",
        "  if validate_key_result is not None:\n",
        "    yield validate_key_result\n",
        "    return\n",
        "\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-02-bc60a180f868\",\n",
        "      location=\"us-central1\",\n",
        "  )\n",
        "  msg1_text1 = types.Part.from_text(text=f\"\"\"Customer Notes for 'SafeHarbor Warehousing':\n",
        "\\\"The applicant is seeking coverage for their 50,000 sq ft warehouse. The business is 5 years old. The building is a concrete tilt-up structure, originally built in 2010. They store a variety of non-hazardous dry goods.\n",
        "Fire safety measures include a full sprinkler system, a centrally monitored fire alarm, and documented annual inspections by a certified third party.\n",
        "Security measures include a 24/7 centrally monitored burglar alarm, comprehensive security camera coverage of the interior and exterior, a fully fenced perimeter, and nightly patrols by a contracted security guard service.\n",
        "The company reports no major property or liability losses in their 5-year history. They have specifically asked to ensure their new automated shelving and retrieval system, installed last month, is adequately covered under the policy.\\\"\n",
        "Your Task:\n",
        "1. Briefly summarize the key details of the 'SafeHarbor Warehousing' business and its existing safety measures.\n",
        "2. Based *only* on the notes provided, identify any immediate questions an underwriter should ask or potential risk factors they should consider further.\n",
        "Present the summary first, then the questions/risk factors as bullet points.\"\"\")\n",
        "  si_text1 = types.Part.from_text(text=f\"\"\"You are an expert AI assistant for an insurance underwriting department.\n",
        "Your primary goal is to help underwriters by accurately and concisely summarizing client information and highlighting potential risk factors.\n",
        "Maintain a professional and objective tone.\n",
        "Focus only on the information provided in the prompt. Do not invent details.\"\"\")\n",
        "\n",
        "\n",
        "  model = \"gemini-2.0-flash-001\"\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        msg1_text1\n",
        "      ]\n",
        "    ),\n",
        "  ]\n",
        "\n",
        "  for prev_msg in history:\n",
        "    role = \"user\" if prev_msg[\"role\"] == \"user\" else \"model\"\n",
        "    parts = utils.get_parts_from_message(prev_msg[\"content\"])\n",
        "    if parts:\n",
        "      contents.append(types.Content(role=role, parts=parts))\n",
        "\n",
        "  if message:\n",
        "    contents.append(\n",
        "        types.Content(role=\"user\", parts=utils.get_parts_from_message(message))\n",
        "    )\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "      temperature=1,\n",
        "      top_p=1,\n",
        "      max_output_tokens=8192,\n",
        "      safety_settings=[\n",
        "          types.SafetySetting(\n",
        "              category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "              threshold=\"OFF\"\n",
        "          ),\n",
        "          types.SafetySetting(\n",
        "              category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "              threshold=\"OFF\"\n",
        "          ),\n",
        "          types.SafetySetting(\n",
        "              category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "              threshold=\"OFF\"\n",
        "          ),\n",
        "          types.SafetySetting(\n",
        "              category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "              threshold=\"OFF\"\n",
        "          )\n",
        "      ],\n",
        "      system_instruction=[si_text1],\n",
        "  )\n",
        "\n",
        "  results = []\n",
        "  for chunk in client.models.generate_content_stream(\n",
        "      model=model,\n",
        "      contents=contents,\n",
        "      config=generate_content_config,\n",
        "  ):\n",
        "    if chunk.candidates and chunk.candidates[0] and chunk.candidates[0].content:\n",
        "      results.extend(\n",
        "          utils.convert_content_to_gr_type(chunk.candidates[0].content)\n",
        "      )\n",
        "      if results:\n",
        "        yield results\n",
        "\n",
        "with gr.Blocks(theme=utils.custom_theme) as demo:\n",
        "  with gr.Row():\n",
        "    gr.HTML(utils.public_access_warning)\n",
        "  with gr.Row():\n",
        "    with gr.Column(scale=1):\n",
        "      with gr.Row():\n",
        "        gr.HTML(\"<h2>Welcome to Vertex AI GenAI App!</h2>\")\n",
        "      with gr.Row():\n",
        "        gr.HTML(\"\"\"This prototype was built using your Vertex AI Studio prompt.\n",
        "            Follow the steps and recommendations below to begin.\"\"\")\n",
        "      with gr.Row():\n",
        "        gr.HTML(utils.next_steps_html)\n",
        "\n",
        "    with gr.Column(scale=2, variant=\"panel\"):\n",
        "      gr.ChatInterface(\n",
        "          fn=generate,\n",
        "          title=\"Insurance Underwriting Summary\",\n",
        "          type=\"messages\",\n",
        "          multimodal=True,\n",
        "      )\n",
        "  demo.launch(show_error=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "T17wH71X1sFk",
        "outputId": "59f81495-73b9-4584-d5f2-ecdc12d6480e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d145bb62312fd0790b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d145bb62312fd0790b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}